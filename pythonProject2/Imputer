df = pd.read_csv('hospital_deaths_train.csv')
df = df.drop('recordid', axis=1)
X = df.drop('In-hospital_death', axis=1)
y = df['In-hospital_death']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train = X_train.reset_index(drop=True)
y_train = y_train.reset_index(drop=True)
df_train = pd.concat([y_train, X_train], axis=1)

X_test = X_test.reset_index(drop=True)
y_test = y_test.reset_index(drop=True)
df_test = pd.concat([y_test, X_test], axis=1)


binary_cols = []
for col in df_train.columns:
    unique_vals = df_train[col].unique()
    if len(unique_vals) <= 3:
        binary_cols.append(col)

#print("Binary columns:", binary_cols)
binary_cols = [col for col in binary_cols if col not in ['MechVentDuration', 'MechVentLast8Hour', 'UrineOutputSum', 'In-hospital_death']]
       
binary_medians = {}

for col in binary_cols:
    col_median = df_train[col].median(skipna=True)
    #binary_medians.append(col_median)
    df_train[col] = df_train[col].fillna(col_median)
    binary_medians[col] = col_median


corr_threshold = 0.05

corr_with_target = df_train.corr()['In-hospital_death']

cols_to_impute_less = corr_with_target[(corr_with_target < corr_threshold) & (corr_with_target > -corr_threshold)].index.tolist()

for coll in ['MechVentDuration', 'MechVentLast8Hour', 'UrineOutputSum', 'In-hospital_death']:
    if coll in cols_to_impute_less:
        cols_to_impute_less.remove(coll)
        
imputer_less = KNNImputer(n_neighbors=5)

for col in cols_to_impute_less:
    if df_train[col].isna().sum() != 0: 
        corr_with_col = df_train.corr()[col].abs()
        top_cols = corr_with_col.sort_values(ascending=False).iloc[1:11].index.tolist()
        df_train[col] = imputer_less.fit_transform(df_train[top_cols])[:, 0]

imputer_less.fit(df_train[cols_to_impute_less])


corr_threshold = 0.05

corr_with_target = df_train.corr()['In-hospital_death'].abs()

cols_to_impute_more = corr_with_target[corr_with_target > corr_threshold].index.tolist()

for coll in ['MechVentDuration', 'MechVentLast8Hour', 'UrineOutputSum', 'In-hospital_death']:
    if coll in cols_to_impute_more:
        cols_to_impute_more.remove(coll)

imputer_more = KNNImputer(n_neighbors=5)

for col in cols_to_impute_more:
    if df_train[col].isna().sum() != 0:  
        corr_with_col = X_train.corr()[col].abs()
        top_cols = corr_with_col.sort_values(ascending=False).iloc[1:11].index.tolist()
        df_train[col] = imputer_more.fit_transform(df_train[top_cols])[:, 0]

imputer_more.fit(df_train[cols_to_impute_more])

# Getting the most correlated features
target_corr = df_train.corr().abs()['MechVentLast8Hour']
sorted_corr = target_corr.sort_values(ascending=False)
last8cor = sorted_corr[:30].index.tolist()

elements_to_remove = ['UrineOutputSum', 'MechVentDuration', 'In-hospital_death']
last8cor = list(filter(lambda x: x not in elements_to_remove, last8cor))

# Keeping only these features for prediction
new = df_train.dropna(subset=['MechVentLast8Hour'], inplace=False)
new = new[last8cor]

# Subsetting to get the rows with NaN MechVentLast8Hour
new2 = df_train[df_train['MechVentLast8Hour'].isna()]
new2 = new2[last8cor]

# Making the preciction using Logistic Regression
clf = LogisticRegression(max_iter=1500)

new_l = new['MechVentLast8Hour']
new_f = new.drop(['MechVentLast8Hour'], axis=1)

new2_f = new2.drop(['MechVentLast8Hour'], axis=1)
new2_l = new2['MechVentLast8Hour']

clf.fit(new_f, new_l)
preds = clf.predict(new2_f)

# Filling the data with the result
s = pd.Series(preds)
s.index = new2.index

df_train['MechVentLast8Hour'] = df_train['MechVentLast8Hour'].fillna(s)


# Getting the most correlated features with MechVentDuration
target_corr = df_train.corr().abs()['MechVentDuration']
sorted_corr = target_corr.sort_values(ascending=False)
last8cor = sorted_corr[:30].index.tolist()

elements_to_remove = ['UrineOutputSum', 'In-hospital_death']
last8cor = list(filter(lambda x: x not in elements_to_remove, last8cor))

# Leaving out NaN's for prediction
new = df_train.dropna(subset=['MechVentDuration'], inplace=False)
new = new[last8cor]

# Rows with NaN values
new2 = df_train[df_train['MechVentDuration'].isna()]
new2 = new2[last8cor]

# Making the prediction using XGBoost
clf = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.07,
                       max_depth=3, alpha=10, n_estimators=150)

new_l = new['MechVentDuration']
new_f = new.drop(['MechVentDuration'], axis=1)

new2_f = new2.drop(['MechVentDuration'], axis=1)
new2_l = new2['MechVentDuration']

clf.fit(new_f, new_l)
preds = clf.predict(new2_f)

# Filling out the data one more time
s = pd.Series(preds)
s.index = new2.index

df_train['MechVentDuration'] = df_train['MechVentDuration'].fillna(s)


#Doing the same steps for UrineOutputSum
target_corr = df_train.corr().abs()['UrineOutputSum']
sorted_corr = target_corr.sort_values(ascending=False)
last8cor = sorted_corr[:20].index.tolist()

elements_to_remove = ['In-hospital_death']
last8cor = list(filter(lambda x: x not in elements_to_remove, last8cor))

new = df_train.dropna(subset=['UrineOutputSum'], inplace=False)
new = new[last8cor]

new2 = df_train[df_train['UrineOutputSum'].isna()]
new2 = new2[last8cor]

clf = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.07,
                       max_depth=3, alpha=10, n_estimators=150)

new_l = new['UrineOutputSum']
new_f = new.drop(['UrineOutputSum'], axis=1)

new2_f = new2.drop(['UrineOutputSum'], axis=1)
new2_l = new2['UrineOutputSum']

clf.fit(new_f, new_l)
preds = clf.predict(new2_f)
preds = preds.astype(int)

s = pd.Series(preds)
s.index = new2.index

df_train['UrineOutputSum'] = df_train['UrineOutputSum'].fillna(s)

#Scaling the Data
scaler = MinMaxScaler()
y_train = df_train['In-hospital_death']
X_train = df_train.drop('In-hospital_death', axis=1)
X_train_scaled = scaler.fit_transform(X_train)
X_train_scaled = pd.DataFrame(X_train_scaled, columns = X_train.columns)
df_train_scaled = pd.concat([y_train, X_train_scaled], axis=1)


#Balancing the Data
df_train_scaled_l = df_train_scaled['In-hospital_death']
df_train_scaled_f = df_train_scaled.drop(['In-hospital_death'], axis = 1)
sm = RandomOverSampler(random_state=42)
balanced_train_f, balanced_train_l = sm.fit_resample(df_train_scaled_f, df_train_scaled_l)
df_train_final = pd.concat([balanced_train_l, balanced_train_f], axis =1)

y_train_final = df_train_final['In-hospital_death']
X_train_final = df_train_final.drop('In-hospital_death', axis=1)

if 'recordid' in X_test.columns:
    X_test = X_test.drop(['recordid'], axis = 'columns')

for key in X_test.keys():
    if key not in X_train_final.keys():        
        X_test = X_test.drop([key], axis = 'columns')

for key in X_train_final.keys():
    if key not in X_test.keys():
        X_test[f'{key}'] = np.nan
        
        
for col, fill_val in binary_medians.items():
    if col in X_test.columns:
        X_test[col].fillna(fill_val, inplace=True)

X_test[cols_to_impute_less] = imputer_less.transform(X_test[cols_to_impute_less])
X_test[cols_to_impute_more] = imputer_more.transform(X_test[cols_to_impute_more])
