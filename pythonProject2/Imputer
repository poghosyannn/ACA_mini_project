from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier


svmrbf = SVC(kernel = 'rbf', C=6, gamma=0.02, probability=False)
svmpol = SVC(kernel = 'poly')
rndfr = RandomForestClassifier(n_estimators=300)
logr = LogisticRegression(C=0.5, penalty = 'l1', solver = 'saga')
qda = QuadraticDiscriminantAnalysis()
ada = AdaBoostClassifier(n_estimators=230)

voting = VotingClassifier(estimators= [('svmrbf', svmrbf), ('svmpol', svmpol), ('rndfr', rndfr), ('logr', logr), 
                                       ('qda', qda), ('ada', ada)], voting = 'hard')


df = pd.read_csv('hospital_deaths_train.csv')
df = df.drop('recordid', axis=1)
X = df.drop('In-hospital_death', axis=1)
y = df['In-hospital_death']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train = X_train.reset_index(drop=True)
y_train = y_train.reset_index(drop=True)
df_train = pd.concat([y_train, X_train], axis=1)

X_test = X_test.reset_index(drop=True)
y_test = y_test.reset_index(drop=True)
df_test = pd.concat([y_test, X_test], axis=1)


binary_cols = []
for col in df_train.columns:
    unique_vals = df_train[col].unique()
    if len(unique_vals) <= 3:
        binary_cols.append(col)

#print("Binary columns:", binary_cols)
binary_cols = [col for col in binary_cols if col not in ['MechVentDuration', 'MechVentLast8Hour', 'UrineOutputSum', 'In-hospital_death']]
       
binary_medians = {}

for col in binary_cols:
    col_median = df_train[col].median(skipna=True)
    #binary_medians.append(col_median)
    df_train[col] = df_train[col].fillna(col_median)
    binary_medians[col] = col_median


corr_threshold = 0.05

corr_with_target = df_train.corr()['In-hospital_death']

cols_to_impute_less = corr_with_target[(corr_with_target < corr_threshold) & (corr_with_target > -corr_threshold)].index.tolist()

for coll in ['MechVentDuration', 'MechVentLast8Hour', 'UrineOutputSum', 'In-hospital_death']:
    if coll in cols_to_impute_less:
        cols_to_impute_less.remove(coll)
        
imputer_less = KNNImputer(n_neighbors=5)

for col in cols_to_impute_less:
    if df_train[col].isna().sum() != 0: 
        corr_with_col = df_train.corr()[col].abs()
        top_cols = corr_with_col.sort_values(ascending=False).iloc[1:11].index.tolist()
        df_train[col] = imputer_less.fit_transform(df_train[top_cols])[:, 0]

imputer_less.fit(df_train[cols_to_impute_less])


corr_threshold = 0.05

corr_with_target = df_train.corr()['In-hospital_death'].abs()

cols_to_impute_more = corr_with_target[corr_with_target > corr_threshold].index.tolist()

for coll in ['MechVentDuration', 'MechVentLast8Hour', 'UrineOutputSum', 'In-hospital_death']:
    if coll in cols_to_impute_more:
        cols_to_impute_more.remove(coll)

imputer_more = KNNImputer(n_neighbors=5)

for col in cols_to_impute_more:
    if df_train[col].isna().sum() != 0:  
        corr_with_col = X_train.corr()[col].abs()
        top_cols = corr_with_col.sort_values(ascending=False).iloc[1:11].index.tolist()
        df_train[col] = imputer_more.fit_transform(df_train[top_cols])[:, 0]

imputer_more.fit(df_train[cols_to_impute_more])

# Getting the most correlated features
target_corr = df_train.corr().abs()['MechVentLast8Hour']
sorted_corr = target_corr.sort_values(ascending=False)
last8cor = sorted_corr[:30].index.tolist()

elements_to_remove = ['UrineOutputSum', 'MechVentDuration', 'In-hospital_death']
last8cor = list(filter(lambda x: x not in elements_to_remove, last8cor))
l8cor = last8cor.copy()

# Keeping only these features for prediction
new = df_train.dropna(subset=['MechVentLast8Hour'], inplace=False)
new = new[last8cor]

# Subsetting to get the rows with NaN MechVentLast8Hour
new2 = df_train[df_train['MechVentLast8Hour'].isna()]
new2 = new2[last8cor]

# Making the preciction using Logistic Regression
clf_Last8 = LogisticRegression(max_iter=1500)

new_l = new['MechVentLast8Hour']
new_f = new.drop(['MechVentLast8Hour'], axis=1)

new2_f = new2.drop(['MechVentLast8Hour'], axis=1)
new2_l = new2['MechVentLast8Hour']

clf_Last8.fit(new_f, new_l)
preds = clf_Last8.predict(new2_f)

# Filling the data with the result
s = pd.Series(preds)
s.index = new2.index

df_train['MechVentLast8Hour'] = df_train['MechVentLast8Hour'].fillna(s)


# Getting the most correlated features with MechVentDuration
target_corr = df_train.corr().abs()['MechVentDuration']
sorted_corr = target_corr.sort_values(ascending=False)
last8cor = sorted_corr[:30].index.tolist()

elements_to_remove = ['UrineOutputSum', 'In-hospital_death']
last8cor = list(filter(lambda x: x not in elements_to_remove, last8cor))

durcor = last8cor.copy()


# Leaving out NaN's for prediction
new = df_train.dropna(subset=['MechVentDuration'], inplace=False)
new = new[last8cor]

# Rows with NaN values
new2 = df_train[df_train['MechVentDuration'].isna()]
new2 = new2[last8cor]

# Making the prediction using XGBoost
clf_Duration = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.07,
                       max_depth=3, alpha=10, n_estimators=150)

new_l = new['MechVentDuration']
new_f = new.drop(['MechVentDuration'], axis=1)

new2_f = new2.drop(['MechVentDuration'], axis=1)
new2_l = new2['MechVentDuration']

clf_Duration.fit(new_f, new_l)
preds = clf_Duration.predict(new2_f)

# Filling out the data one more time
s = pd.Series(preds)
s.index = new2.index

df_train['MechVentDuration'] = df_train['MechVentDuration'].fillna(s)


#Doing the same steps for UrineOutputSum
target_corr = df_train.corr().abs()['UrineOutputSum']
sorted_corr = target_corr.sort_values(ascending=False)
last8cor = sorted_corr[:20].index.tolist()


elements_to_remove = ['In-hospital_death']
last8cor = list(filter(lambda x: x not in elements_to_remove, last8cor))

urcor = last8cor.copy()

new = df_train.dropna(subset=['UrineOutputSum'], inplace=False)
new = new[last8cor]

new2 = df_train[df_train['UrineOutputSum'].isna()]
new2 = new2[last8cor]

clf_Urine = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.07,
                       max_depth=3, alpha=10, n_estimators=150)

new_l = new['UrineOutputSum']
new_f = new.drop(['UrineOutputSum'], axis=1)

new2_f = new2.drop(['UrineOutputSum'], axis=1)
new2_l = new2['UrineOutputSum']

clf_Urine.fit(new_f, new_l)
preds = clf_Urine.predict(new2_f)
preds = preds.astype(int)

s = pd.Series(preds)
s.index = new2.index

df_train['UrineOutputSum'] = df_train['UrineOutputSum'].fillna(s)

#Scaling the Data
scaler = MinMaxScaler()
y_train = df_train['In-hospital_death']
X_train = df_train.drop('In-hospital_death', axis=1)
X_train_scaled = scaler.fit_transform(X_train)
X_train_scaled = pd.DataFrame(X_train_scaled, columns = X_train.columns)
df_train_scaled = pd.concat([y_train, X_train_scaled], axis=1)


#Balancing the Data
df_train_scaled_l = df_train_scaled['In-hospital_death']
df_train_scaled_f = df_train_scaled.drop(['In-hospital_death'], axis = 1)
sm = RandomOverSampler(random_state=42)
balanced_train_f, balanced_train_l = sm.fit_resample(df_train_scaled_f, df_train_scaled_l)
df_train_final = pd.concat([balanced_train_l, balanced_train_f], axis =1)

y_train_final = df_train_final['In-hospital_death']
X_train_final = df_train_final.drop('In-hospital_death', axis=1)

if 'recordid' in X_test.columns:
    X_test = X_test.drop(['recordid'], axis = 'columns')

for key in X_test.keys():
    if key not in X_train_final.keys():        
        X_test = X_test.drop([key], axis = 'columns')

for key in X_train_final.keys():
    if key not in X_test.keys():
        X_test[f'{key}'] = np.nan
        
        
for col, fill_val in binary_medians.items():
    if col in X_test.columns:
        X_test[col].fillna(fill_val, inplace=True)

X_test[cols_to_impute_less] = imputer_less.transform(X_test[cols_to_impute_less])
X_test[cols_to_impute_more] = imputer_more.transform(X_test[cols_to_impute_more])





#filling last three features in test dataset
new2dur = X_test[X_test['MechVentDuration'].isna()]
new2dur = new2dur[durcor]

new2l8 = X_test[X_test['MechVentLast8Hour'].isna()]
new2l8 = new2l8[l8cor]

new2ur = X_test[X_test['UrineOutputSum'].isna()]
new2ur = new2ur[urcor]



new2_f_dur = new2dur.drop(['MechVentDuration'], axis=1)
new2_l_dur = new2dur['MechVentDuration']

new2_f_l8 = new2l8.drop(['MechVentLast8Hour'], axis=1)
new2_l_l8 = new2l8['MechVentLast8Hour']

new2_f_ur = new2ur.drop(['UrineOutputSum'], axis=1)
new2_l_ur = new2ur['UrineOutputSum']


ur_preds = clf_Urine.predict(new2_f_ur)
l8_preds = clf_Last8.predict(new2_f_l8)
dur_preds = clf_Duration.predict(new2_f_dur)


s = pd.Series(l8_preds)
s.index = new2l8.index

X_test['MechVentLast8Hour'] = X_test['MechVentLast8Hour'].fillna(s)


s = pd.Series(ur_preds)
s.index = new2ur.index

X_test['UrineOutputSum'] = X_test['UrineOutputSum'].fillna(s)


s = pd.Series(dur_preds)
s.index = new2dur.index

X_test['MechVentDuration'] = X_test['MechVentDuration'].fillna(s)


X_test = pd.DataFrame(scaler.transform(X_test), columns = c.columns)



from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, matthews_corrcoef

accuracy = accuracy_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
specificity = precision_score(y_test, y_pred)
auc = roc_auc_score(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)

# Print the evaluation metrics
print('Accuracy score:', accuracy)
print('Recall score:', recall)
print('Specificity score:', specificity)
print('AUC score:', auc)
print('MCC score:', mcc)
