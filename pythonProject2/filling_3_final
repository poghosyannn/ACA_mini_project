import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.impute import KNNImputer
import xgboost as xgb
from sklearn.linear_model import LogisticRegression


data = pd.read_csv('hospital_deaths_train.csv')
data = data.drop(['recordid'], axis = 1)


corr_threshold = 0.05

corr_with_target = data.corr()['In-hospital_death']

cols_to_impute = corr_with_target[(corr_with_target < corr_threshold) & (corr_with_target > -corr_threshold)].index.tolist()

imputer = KNNImputer(n_neighbors=5)
data[cols_to_impute] = imputer.fit_transform(data[cols_to_impute])



corr_threshold = 0.05

# Get the correlation between each feature and the target column
corr_with_target = data.corr()['In-hospital_death'].abs()

# Get the columns whose correlation with the target column is higher than the threshold
cols_to_impute = corr_with_target[corr_with_target > corr_threshold].index.tolist()
cols_to_impute.remove('In-hospital_death')

# Create a KNNImputer object with n_neighbors=10
imputer = KNNImputer(n_neighbors=5)

# Fill the NaN values for each column based on the ten highest correlated columns with that column
for col in cols_to_impute:
    if col not in ['CSRU', 'MechVentDuration', 'MechVentLast8Hour', 'UrineOutputSum']:
        corr_with_col = data.corr()[col].abs()
        top_cols = corr_with_col.sort_values(ascending=False).iloc[1:11].index.tolist()
        data[col] = imputer.fit_transform(data[top_cols])[ :,0]
        

#Getting the most correlated features
target_corr = data.corr().abs()['MechVentLast8Hour']
sorted_corr = target_corr.sort_values(ascending=False)
last8cor = sorted_corr[:30].index.tolist()

elements_to_remove =['UrineOutputSum', 'MechVentDuration', 'In-hospital_death']
last8cor = list(filter(lambda x: x not in elements_to_remove, last8cor))

#Keeping only these features for prediction
new = data.dropna(subset=['MechVentLast8Hour'], inplace=False)
new = new[last8cor]

#Subsetting to get the rows with NaN MechVentLast8Hour
new2 = data[data['MechVentLast8Hour'].isna()]
new2 = new2[last8cor]

#Making the preciction using Logistic Regression
clf = LogisticRegression(max_iter=500)

new_l = new['MechVentLast8Hour']
new_f = new.drop(['MechVentLast8Hour'], axis = 1)

new2_f = new2.drop(['MechVentLast8Hour'], axis = 1)
new2_l = new2['MechVentLast8Hour']

clf.fit(new_f, new_l)
preds = clf.predict(new2_f)

#Filling the data with the result
s = pd.Series(preds)
s.index = new2.index

data['MechVentLast8Hour'] = data['MechVentLast8Hour'].fillna(s)



#Getting the most correlated features with MechVentDuration
target_corr = data.corr().abs()['MechVentDuration']
sorted_corr = target_corr.sort_values(ascending=False)
last8cor = sorted_corr[:30].index.tolist()

elements_to_remove =['UrineOutputSum', 'In-hospital_death']
last8cor = list(filter(lambda x: x not in elements_to_remove, last8cor))

#Leaving out NaN's for prediction
new = data.dropna(subset=['MechVentDuration'], inplace=False)
new = new[last8cor]

#Rows with NaN values
new2 = data[data['MechVentDuration'].isna()]
new2 = new2[last8cor]

#Making the regression using XGBoost
clf = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.07,
                max_depth = 3, alpha = 10, n_estimators = 150)

new_l = new['MechVentDuration']
new_f = new.drop(['MechVentDuration'], axis = 1)

new2_f = new2.drop(['MechVentDuration'], axis = 1)
new2_l = new2['MechVentDuration']

clf.fit(new_f, new_l)
preds = clf.predict(new2_f)

#Filling out the data one more time
s = pd.Series(preds)
s.index = new2.index

data['MechVentDuration'] = data['MechVentDuration'].fillna(s)


target_corr = data.corr().abs()['UrineOutputSum']
sorted_corr = target_corr.sort_values(ascending=False)
last8cor = sorted_corr[:20].index.tolist()

elements_to_remove =['In-hospital_death']
last8cor = list(filter(lambda x: x not in elements_to_remove, last8cor))

new = data.dropna(subset=['UrineOutputSum'], inplace=False)
new = new[last8cor]

new2 = data[data['UrineOutputSum'].isna()]
new2 = new2[last8cor]


clf = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.07,
                max_depth = 3, alpha = 10, n_estimators = 150)


new_l = new['UrineOutputSum']
new_f = new.drop(['UrineOutputSum'], axis = 1)

new2_f = new2.drop(['UrineOutputSum'], axis = 1)
new2_l = new2['UrineOutputSum']

clf.fit(new_f, new_l)
preds = clf.predict(new2_f)
preds = preds.astype(int)

s = pd.Series(preds)
s.index = new2.index

data['UrineOutputSum'] = data['UrineOutputSum'].fillna(s)
